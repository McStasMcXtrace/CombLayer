\subsection{Variance reduction}

\subsubsection{New way: FW-CADIS}
\nomenclature{CADIS}{Consistent Adjoint Driven Importance Sampling}
We consider our result~$R$ to be a convolution of some
flux~$\Psi(\vec{P})$ determined by all the parameters~$\vec{P}$
(position~$\vec{r}$, energy~$E$, angular
coordinate~$\Phi\vec{\Omega}$) and a determenistic cross
section~$\sigma_D(\vec{P})$ that relates to that:
\begin{equation}
  \label{eq:vr:result}
  R = \int \Psi(\vec{P}) \sigma_D(\vec{P}) d\vec{P}
\end{equation}

% 2:12
That allowes you to have a selectivity because a neutron must cross a
certain surface or have a certain energy or direction and this is encoded into $\sigma_D(\vec{P})$.

\paragraph{Cross section}
$\sigma_D(\vec{P})$ is a {\em determenistic} cross section, which constructed to be representative of the quantity
that the simulation is going to measure. For example, if the flux going through a cell for the energy between
\SIrange[range-phrase=\ and\ ]{1}{2}{\electronvolt} is the quantity of interest, then
$\sigma_D=1$ when the particle is located in the given cell and energy is between these two values,
otherwise $\sigma_D=0$.

\bigskip

We will now imply the integral over $d\vec{P}$, and imply that there is a unique Hamiltonian,
that can express the flux at all points in the phase space are equal to the source value. It is basically
second order differential equation. The transport equations can be written as:
% integration is implied here
\begin{equation}
  \label{eq:vr:Hamiltonian}
  H \Psi = q
\end{equation}


So we operate on the whole flux, and this allows the field to be evolved.
Hamiltonian always operates on flux in order to evolve it to a new type.
We will assume that we start at some source at time zero and we will evolve it, and \eqref{eq:vr:Hamiltonian} has to
hold for all time since we have conservation.

Conjugated form:
\begin{equation}
  H^* \Psi^*  =  \vec{q}^{\,*} 
\end{equation}

This is the general form. As an example, for a simple neutron that under,
elastic scattering and absorption only we will see that equation \eqref{eq:vr:Hamiltonian} becomes
the classical  scattering equation~\cite[Eq.\,1]{arXiv:1612.00793}:

\begin{eqnarray}
  \lbrack\Omega \cdot \nabla + \Sigma_t(\vec{r},E)\rbrack \, \Psi(r,\hat\Omega,E) & = & \int^\infty_0 dE' \int_{4\pi}
  d\hat\Omega' \, \Sigma_s(\vec{r},E' \to E,\hat\Omega' \cdot \hat\Omega) \, \Psi(\vec{r},\hat\Omega',E') + q(\vec{r},\hat\Omega,E) \\
  \lbrack-\hat\Omega \cdot \nabla + \Sigma_t(\vec{r},E)\rbrack \, \Psi^*(\vec{r},\hat\Omega,E) & = & \int^\infty_0 dE' \int_{4\pi}
  d\hat\Omega' \, \Sigma_s(\vec{r},E \to E',\hat\Omega \cdot \hat\Omega') \, \Psi^*(\vec{r},\hat\Omega',E') + q^*(\vec{r},\hat\Omega,E) 
\end{eqnarray}


These two cases are the forward going (i.e. from the source to the tally region) and the backward going from the
tally to the source. Note tha the flux must be the same is we assume reversibility.

We can [with a lot of algebra/Mathematica] show that they obey the identity
\begin{equation}
  < \Psi^*,H,\Psi >  =  <\Psi, H^*, \Psi^*> 
\end{equation}

and therefore 
\begin{equation}
  < q,\Psi^* >  =  <q^*,\Psi> 
\end{equation}
where $< >$ is the inner product, which is the integral over $\vec{P}$.

Now if we set $q^* \equiv \Sigma_d$, then we have \alert{check the '\{' symbol and '$q^,$' in the line below}

\begin{equation}
<q^*,\Psi>  = <\Sigma_d,\{< q,\Psi^* >  =  R = <q^,\Psi^*> 
\end{equation}

this is the same as
\begin{equation*}
  R = \int \Psi(\vec{P}) q^*(\vec{P}) d\vec{P}
\end{equation*}

and

\begin{equation*}
  R = \int \Psi^*(\vec{P}) q(\vec{P}) d\vec{P}
\end{equation*}

\paragraph{Assumptions}
We have made the following two assumptions:
\begin{enumerate}
\item Time reversal for neutrons completely valid;
\item If we start with the neutron at our tally point and run it backwards, we get exactly the same thing as running it forwards.
\end{enumerate}
This means that we are operating with one-group/multi-group equations,
i.e. not allowing the neutrons to change energy or allowing the neutrons to change energy only into discrete
probabilities.

This situation is valid if we consider only elastic scattering and absorption processes, and we believe that
this approximation should be enough for variance reduction purposes.

\bigskip


% 6:37
Now we state that absorption is all absorption capture + all loss, where a neutron losses energy and falls out of the group
(i.e. it's much bigger absorption cross section than the stated one, see $\sigma_{A}^\dagger$ below).

The contribution of the individual piece of flux to $R$ (what we really want to know) can be expressed by
\begin{equation}
  \label{eq:vr:w}
  w(\vec{P}) = \frac{R}{\Psi^*(\vec{P})}
\end{equation}
where $\Psi^*(\vec{P})$ is adjoined flux (backward going flux with respect to $\Psi(\vec{P})$).
ans $w$ is the inverse of the probability importance of a region in $\vec{P}$.

At the same time we know that we can express our weight as
\begin{equation}
  \label{eq:vr:w0}
  w = w_0 \cdot q(\vec{P})
\end{equation}
$q(\vec{P})$ we can calculate using the Hamiltonian in \eqref{eq:vr:Hamiltonian}.

This leaves us with the new expression for $R$ (\alert{Where did we lose $\Phi$?}):
\begin{equation}
  \label{eq:vr:R1}
  R = \int d\Omega \int d\vec{r} \int dE \, \Psi(\vec{r},E,\Omega) \, f(\vec{r},E,\Omega)
\end{equation}
where $f(\vec{r},E,\Omega)$ is an approximation \alert{of what?} from the CADIS paper. \todo{Explain}
They can find an approximation for this based on the true weight of the number of particles in the given cell
(times the Monte Carlo density).

CADIS is the name of the program they wrote.

First, we need to find $\Psi$, but we are not going to find it because it means we need to run full simulation.
Therefore we will only find $\Psi$ in a one-group approximation.
To do this, we need $\sigma_{T}$ and $\sigma_{A}^\dagger$, where

\begin{description}
\item[$\sigma_{T}$] The total interaction cross section [including all absorption terms].
\item[$\sigma_{A}^\dagger$] Probability that a neutron is lost from the group {\em plus} the probability that a neutron is being absorbed.
\end{description}

% 10:04
CADIS divides energy range into 33 energy bins. CombLayer does not support so many~(SA says he tried 7).

\bigskip

When we run our variance reduction, we are going to calculate two things:
\begin{itemize}
\item We are going to tell the program what $\sigma_D$ is, and that's easy because it's defined by the tally.
\item We have to roughly define where the source of our particles is going to start from. In principle that's where the proton start,
  and that would be a good thing except that in reality that's not the most efficient thing at all.
  You can multiply the variance reductions together, therefore it's better to define several weight window meshes~(i.e.
  first~--- from Target to Moderator, second~--- from Moderator to Monolith Insert, third~--- Insert to Bunker Wall etc).
\end{itemize}

So, you can have as many source points as you like, as long as you have an adjoint point to go with it.
Not all sources are points: some are planes, some are cylinders. At the moment in CL there are 3 types of shapes: a point, a plane, a cone.
More shapes and head rules will be added in the future.
Equally, same shapes can be set as the adjoint sources~(where we are focusing into).
Points work reasonably well, but should be extended to cones/cylinders.

The user defines the source point and the adjoint point, and CombLayer computes $R$ based on \eqref{eq:vr:R1} and
weight based on~\eqref{eq:vr:w}\dots\ and you are done!

\paragraph{Normalisation}

% 13:26
Previous one sided variance reduction, not base on both a source term
and an adjoint form, lead to an unbiased variance reduction that is
not normalized. If the source and the tally variance reduction terms
are both used then the above theory does not give rise to any need to
do normalization. However, due to the need to issues like doing a
quick and simple simulation were a source is approximated or multiple
tallies normalization may be required. For example if a simulation is
started from the ESS target but the flux down a beamline is required
two sources may be used e.g one at the target and one at the exit of
the monolith. There is currently no weighting system for the
contribution of both variances [which should be done using the
  probability of exiting the monolith] and thus the variance reduction
mesh can be significantly mis-scaled.

Therefore, there is the option to re-normalized the whole variance reduction mesh by adding the flag
{\tt --wwgNorm AValue BValue} such that the new normalization range between low/high is limited between A and B.


There is a rounding error of the order \SIrange{10}{15}{\percent}.
It comes mainly because sometimes we divide very small numbers (of the range \num[retain-unity-mantissa=false]{1e-30}). So, you can do normalisation here, but
SA can't be bothered most of the time.

\bigskip

That's the principle of the variance reduction. In addition, there is a whole pile of tools which can help you out when things
are not going in the appropriate way.
For example, you can change the density of the entire model (for the variance reduction only, not for the real run).
If you decrease it~(say, to \SI{80}{\percent}), it would oversample the area in the end\footnote{See the {\tt --wwgCalc} flag in \secref{sec:vr:cadis:mesh}.}.

You can also put a limit to indicate that you do not want to write variance reduction down to \num[retain-unity-mantissa=false]{1e-317}, because it overpopulates too much the given cell. Normally, this limit is \numrange[retain-unity-mantissa=false]{1e-46}{1e-20}.

% 16:15.482 - start recording desktop

\subsection{How to use it}
There are two types of variance reduction in MCNP and in CombLayer.
One is a cell-based, the other one is a mesh-based variance reduction.
SA had modified his MCNP version to allow both at the same time.

\subsubsection{Mesh-based variance reduction}
\label{sec:vr:cadis:mesh}
\git{7348754} \label{bash:vr:cadis:mesh:run}
\begin{bash}
ess -r -w -wWWG \ 
 --weightSource 'Vec3D(1000.0, 0.0, 14.0)' \
 --weightSource 'Vec3D(1500.0, 0.0, 14.0)' \
 --weightPlane 'Vec3D(1500.0, 0.0, 14.0)' 'Vec3D(-1, 0, 0)' \
 --wwgCalc SS0 1.0 \
 --wwgCalc TP0 -2 1 2 -4\
 --wwgCADIS 'Vec3D(1000.0, 0.0, 14.0)' \
 --wwgXMesh 1000 40 1600 \
 --wwgYMesh -50 10 50 \
 --wwgZMesh -100 20 100 \
 --wwgE 1.0 \
 --wwgVTK testWWG.vtk \
   a
\end{bash}

\begin{description}
\item[-w] needs to be the first flag in the list of biasing-related flags
\item[-wWWG] we are interested in the mesh-based weight window generator
\item[--weightSource] defines a (source or adjoint) {\em single point} in space. It's possible to define as many as necessary, and not all of them should be used.
  Here we defined two point sources.
\item[--wwg{[XYZ]}Mesh] defines a mesh (if we need it). Format: min nbins max.
\item[--wwgE] defines energy grid with MCNP notation (below \SI{1}{\mega\electronvolt}). There is no variance reduction above last energy bin.
  It is also possible to use the {\tt --weightEnergyType} argument as shown in \secref{sec:vr:cadis:cell}.
\item[--wwgVTK] optionally you can output the mesh file into a VTK file for plotting.
\item[--wwgCalc] define source and adjoined points. We must define at least one source and {\em at least} one adjoined point.
  Syntax:
  \begin{description}
  \item[SS0] First 'S': true source point. 'S0': first point in the list.
  \item[1] means energy range above \SI{1}{\mega\electronvolt} (-1 would mean below \SI{1}{\mega\electronvolt}).
  \item[TP0] First 'T': adjoined point (tally). 'P0': from the 1st plane in the list.
    % 23:00
  \item[-2] define energy grid. Negative number: up till this energy (cut-off energy).
  \item[1] density factor. Normally the trick is to decrease density in order to populate remote cells.
  \item[2] the power of $r^2$. SA does not find this parameter very useful.
  \item[1] absolute minimal weight you can have. If the number is negative, it means the exponent ($10^{-n}$). If it's not negative, it must be between 0 and 1 (remember that weights can not go above 1).
  \end{description}
% 25:45
\item[--wwgCADIS] Finally you better do the CADIS summation~--- the integral over the whole thing. The final weight value has to still
  come from the intrinsic integral point, and that should be the source point in order to do normalisation correctly (SA believes it's semi-redundant, but he is still using it anyway. In principle one should integrate all the source points, weight them and not need this coordinate, but currently SA take one point approximated. It will be changed in the future.)
\end{description}

% 25:15
The source terms must cover the full energy range.
It's completely acceptable that an individual source term does not cover full energy range,
but somewhere you must have at least one other source term that covers the rest.

When you run it, the output is very verbose:
\begin{bash}
...
CADIS norm[7700]:-46.0517 0.693147 == 1577.5 5 -95          WWGWeight::CADISnorm
CADIS norm[7800]:-46.0517 0.693147 == 1592.5 -45 -95        WWGWeight::CADISnorm
CADIS norm[7900]:-46.0517 0.693147 == 1592.5 5 -95          WWGWeight::CADISnorm
sumR== -7.37277 0.000628129                                 WWGWeight::CADISnorm
Min == 0.000314064 0.000314064 1                                  WWG::updateWM
Warning : No WWG normalization step                        WWGControl::wwgNormalize
\end{bash}

% 27:51
Every 100 points during integration it writes you the ratios of contribution of flux to a given point and the source to the given point.
So, it finds that you get about
\num[retain-unity-mantissa=false]{1e9} (0.693147) \todo{1e9 does not correspond to the output}
contributions from the source at the start of the wall, but once you get through the wall you get
\num[retain-unity-mantissa=false]{1e46} (-46.0517) contribution.
You end up with the minimum weight (which is in fact the maximal weight \alert{???}), which is the normalisation factor. \\
sumR are normalisation terms and its value (-7.37277) says we are out of normalisation a bit (therefore we can maybe do something with it).

% 29:12 - ParaView
The weight window is saved in the {\tt wwinp} file and optionally can be exported in a {\tt VTK} file by using the {\tt --wwgVTK} command line argument
as shown in the listing on page \pageref{bash:vr:cadis:mesh:run}.
This {\tt VTK} file can be visualised by an external program like {\tt VisIt} or {\tt ParaView}.

In the input deck, the weight-window parameters are defined as
\begin{deck}
 wwp:n 8 1.4 5 -1 -2 0
\end{deck}
where {\tt switchn=-2}. In the non-modified \mcnp this value indicates that ``the lower weight-window bounds should be read from an external {\tt wwinp} file
containing either cell- or mesh-based lower weight window bounds''.
SA modifies \mcnp, and this value means {\em both} cell and weight.
It's possible to use {\tt switchn=-2} for non-modified \mcnp versions, and the rule is that when you've got outside of the mesh boundary, you score
importance only. In your input file you have a list of the cells and cell weights, and with regular \mcnp you will get a warning saying that the cell weights being ignored.
\mcnp will happily run, and if a particle drops outside of the boundary and has a scatter, you will be warned that importances are being sampled instead of {\tt wwinp} \todo{Show the exact message}
and you will get the default importance which in this case is 1.

\paragraph{Modification of MCNP}
\mcnp uses a single array to mean either the mesh or the cell grid, that's why it can't do both at the same time.
SA added a multiple array in order to be able to have several simplified meshes, which can be put in arbitary way.
These meshes can be ordered.
% 33:30
We thest the first one first. If you want to have a mesh in a mesh, you simply put the final mesh at the top,
so you can have exactly the same behaviour as you currently have, but you can also have much better behaviour in the sence
that two meshes do not need to be orthogonal, they can follow bending in a curving beam line, which is useful\footnote{Especially for LOKI, wich has two \SI{\sim 5}{\degree} bends.}.
Or you can have a fixed mesh around the moderator, which does not have to respect whichever direction of beam line we are taking away.
And SA can have that mesh isolated and separate.

\subsubsection{Old way: cell-based biasing}
\label{sec:vr:cadis:cell}
Cell-based variance reduction is the old method implemented in CombLayer.

\lstinputlisting[language=bash,numbers=none,backgroundcolor=\color{yellow!20},frame=tb]{UserGuide/cell-biasing.sh}

\begin{description}
\item[-C] defines energy cut
\item[--weightEnergyType] defines energy grid. With the {\tt wwg} card you can either use this expression or {\tt --wwgE}.
  If use use the word ``energy'' then the format is energy (0.1), default weight for that bin (0.95). If you drop the word ``energy'' then you just set the energy grid.
  In the given example for energies below \SI{0.1}{\mega\electronvolt} the default weight is 0.95 etc.
\item[--weightPlane] Here we can set two planes
\item[--weightObject] {\tt BBunkerWallMainWall1}: object we are interested in calculating; {\tt TP1}: tally plane 1;
  \mbox{\tt 1.0 0.15 1e-20}: energy above \SI{1}{\mega\electronvolt} (below it we are not interested~--- use default values);
  {\tt 0.15}: density factor; {\tt 1e-20}: minimum \alert{???} % 41:12

\end{description}

Here we need to define an object we are interested in calculating, and the idea is exactly the same as we had previously.
When you run it, it takes longer time to generate the weight window since the implementation is not perfect: it calculates every individual cell and calculate track through it.
In the new method described in \ref{sec:vr:cadis:mesh} SA takes a cell and track a line through it and removes from the need to be calculated every cell it goes through \todo{SA: check}.

In the generated input deck the cells 687--701 belong to the wall and they are being evaluated:
\begin{deck}
wwe:n 0.1 1 10 100 5000
wwp:n 2 1.4 5 0 0 0
#   wwn1:n  wwn2:n  wwn3:n  wwn4:n  wwn5:n
c   c        c        c        c        c
...
685   9.50e-01 8.50e-01 5.00e-01 4.00e-01 3.00e-01
686   9.50e-01 8.50e-01 5.00e-01 4.00e-01 3.00e-01
687   9.50e-01 2.73e-01 1.61e-01 1.29e-01 9.64e-02
688   9.50e-01 2.72e-01 1.60e-01 1.28e-01 9.60e-02
689   9.50e-01 2.95e-01 1.74e-01 1.39e-01 1.04e-01
690   9.50e-01 3.24e-01 1.90e-01 1.52e-01 1.14e-01
691   9.50e-01 3.60e-01 2.12e-01 1.70e-01 1.27e-01
692   9.50e-01 3.63e-01 2.14e-01 1.71e-01 1.28e-01
693   9.50e-01 3.98e-01 2.34e-01 1.87e-01 1.41e-01
694   9.50e-01 4.21e-01 2.48e-01 1.98e-01 1.49e-01
695   9.50e-01 4.72e-01 2.78e-01 2.22e-01 1.67e-01
696   9.50e-01 4.93e-01 2.90e-01 2.32e-01 1.74e-01
697   9.50e-01 5.47e-01 3.22e-01 2.58e-01 1.93e-01
698   9.50e-01 5.85e-01 3.44e-01 2.76e-01 2.07e-01
699   9.50e-01 6.59e-01 3.88e-01 3.10e-01 2.33e-01
700   9.50e-01 7.03e-01 4.13e-01 3.31e-01 2.48e-01
701   9.50e-01 8.07e-01 4.75e-01 3.80e-01 2.85e-01
702   9.50e-01 8.50e-01 5.00e-01 4.00e-01 3.00e-01
\end{deck}

% 42:26